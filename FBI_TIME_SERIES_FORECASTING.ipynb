{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFcV2vzYpb57d0dtb9UHTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SARTHAKCHAKS/FBI_TIME_SERIES_FORECASTING/blob/main/FBI_TIME_SERIES_FORECASTING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SYBM7L4LsJXo",
        "outputId": "cdf711da-6461-4b6c-ef01-5e2ccc14cb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: prophet in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (2.2.2)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from prophet) (0.81)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.12/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Please upload the required files: 'Train.csv' and 'Test.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb25e0db-d217-421f-89b5-3dd60ba08c58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb25e0db-d217-421f-89b5-3dd60ba08c58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Train.csv to Train.csv\n",
            "Saving Test.csv to Test.csv\n",
            "\n",
            "Data files loaded successfully.\n",
            "\n",
            "--- Train Data Head ---\n",
            "          TYPE     HUNDRED_BLOCK NEIGHBOURHOOD         X           Y  \\\n",
            "0  Other Theft  9XX TERMINAL AVE    Strathcona  493906.5  5457452.47   \n",
            "1  Other Theft  9XX TERMINAL AVE    Strathcona  493906.5  5457452.47   \n",
            "2  Other Theft  9XX TERMINAL AVE    Strathcona  493906.5  5457452.47   \n",
            "3  Other Theft  9XX TERMINAL AVE    Strathcona  493906.5  5457452.47   \n",
            "4  Other Theft  9XX TERMINAL AVE    Strathcona  493906.5  5457452.47   \n",
            "\n",
            "    Latitude   Longitude  HOUR  MINUTE  YEAR  MONTH  DAY        Date  \n",
            "0  49.269802 -123.083763  16.0    15.0  1999      5   12  05/12/1999  \n",
            "1  49.269802 -123.083763  15.0    20.0  1999      5    7  05/07/1999  \n",
            "2  49.269802 -123.083763  16.0    40.0  1999      4   23  04/23/1999  \n",
            "3  49.269802 -123.083763  11.0    15.0  1999      4   20  04/20/1999  \n",
            "4  49.269802 -123.083763  17.0    45.0  1999      4   12  04/12/1999  \n",
            "\n",
            "--- Test Template Head ---\n",
            "   YEAR  MONTH                                               TYPE  \\\n",
            "0  2013      6  Vehicle Collision or Pedestrian Struck (with I...   \n",
            "1  2013      6                                   Theft of Vehicle   \n",
            "2  2013      6                                   Theft of Bicycle   \n",
            "3  2013      6                                 Theft from Vehicle   \n",
            "4  2013      6                                        Other Theft   \n",
            "\n",
            "   Incident_Counts  \n",
            "0              NaN  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n",
            "\n",
            "Starting data preprocessing...\n",
            "\n",
            "--- Aggregated Time Series Data Head ---\n",
            "          ds                               TYPE    y\n",
            "0 1999-01-01         Break and Enter Commercial  303\n",
            "1 1999-01-01  Break and Enter Residential/Other  644\n",
            "2 1999-01-01                           Mischief  551\n",
            "3 1999-01-01           Offence Against a Person  338\n",
            "4 1999-01-01                        Other Theft  247\n",
            "Total number of time series: 9\n",
            "\n",
            "Training and forecasting for: Break and Enter Commercial...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/gg6x6t7b.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/wxdrjgi4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=6790', 'data', 'file=/tmp/tmpxpfup3ip/gg6x6t7b.json', 'init=/tmp/tmpxpfup3ip/wxdrjgi4.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_model5hcmuk_4/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/bxc76d8k.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/kzrbnhms.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=80034', 'data', 'file=/tmp/tmpxpfup3ip/bxc76d8k.json', 'init=/tmp/tmpxpfup3ip/kzrbnhms.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_modelkkoz3p02/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/6qf2q5bv.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/xul3i3lf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=17602', 'data', 'file=/tmp/tmpxpfup3ip/6qf2q5bv.json', 'init=/tmp/tmpxpfup3ip/xul3i3lf.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_modelsjij_pe6/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and forecasting for: Break and Enter Residential/Other...\n",
            "\n",
            "Training and forecasting for: Mischief...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/dm25sxd2.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/w8ha99ub.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=58106', 'data', 'file=/tmp/tmpxpfup3ip/dm25sxd2.json', 'init=/tmp/tmpxpfup3ip/w8ha99ub.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_modelytw993e7/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/9794h6f4.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/80hny7pf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=17106', 'data', 'file=/tmp/tmpxpfup3ip/9794h6f4.json', 'init=/tmp/tmpxpfup3ip/80hny7pf.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_modelxje8ma3e/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and forecasting for: Offence Against a Person...\n",
            "\n",
            "Training and forecasting for: Other Theft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/1_19yuuh.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/lbnq0azs.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=23113', 'data', 'file=/tmp/tmpxpfup3ip/1_19yuuh.json', 'init=/tmp/tmpxpfup3ip/lbnq0azs.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_model5ez2gt1t/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/2w5u6v99.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/qr2bbify.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41222', 'data', 'file=/tmp/tmpxpfup3ip/2w5u6v99.json', 'init=/tmp/tmpxpfup3ip/qr2bbify.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_model6zsxv248/prophet_model-20251008175325.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and forecasting for: Theft from Vehicle...\n",
            "\n",
            "Training and forecasting for: Theft of Bicycle...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/hxf6779p.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/48o1gzr2.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=47644', 'data', 'file=/tmp/tmpxpfup3ip/hxf6779p.json', 'init=/tmp/tmpxpfup3ip/48o1gzr2.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_modelsdahiv6b/prophet_model-20251008175326.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/_sdim5sb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpxpfup3ip/wjuuvoii.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=32390', 'data', 'file=/tmp/tmpxpfup3ip/_sdim5sb.json', 'init=/tmp/tmpxpfup3ip/wjuuvoii.json', 'output', 'file=/tmp/tmpxpfup3ip/prophet_model0q6v2a4v/prophet_model-20251008175326.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and forecasting for: Theft of Vehicle...\n",
            "\n",
            "Training and forecasting for: Vehicle Collision or Pedestrian Struck (with Injury)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "17:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating final submission file ---\n",
            "\n",
            "--- Final Submission File Head ---\n",
            "   YEAR  MONTH                                               TYPE  \\\n",
            "0  2013      6  Vehicle Collision or Pedestrian Struck (with I...   \n",
            "1  2013      6                                   Theft of Vehicle   \n",
            "2  2013      6                                   Theft of Bicycle   \n",
            "3  2013      6                                 Theft from Vehicle   \n",
            "4  2013      6                                        Other Theft   \n",
            "\n",
            "   Incident_Counts  \n",
            "0            129.0  \n",
            "1             87.0  \n",
            "2            209.0  \n",
            "3            909.0  \n",
            "4            410.0  \n",
            "Total rows in submission: 162\n",
            "\n",
            "--- SUCCESS ---\n",
            "The forecasting is complete. The results have been saved to:\n",
            "FBI_Time_Series_Forecast_Submission.csv\n",
            "You can download the file from the Colab file explorer or by running the following command:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f9789df-3f4d-4513-940d-bc3d5007390d\", \"FBI_Time_Series_Forecast_Submission.csv\", 5278)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP AND DATA UPLOADING\n",
        "# ==============================================================================\n",
        "\n",
        "# Install the necessary library (Prophet)\n",
        "!pip install prophet openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"Please upload the required files: 'Train.csv' and 'Test.csv'\")\n",
        "# Use the files.upload() function to allow the user to upload the files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if both files were uploaded\n",
        "if 'Train.csv' not in uploaded:\n",
        "    print(\"\\nERROR: 'Train.csv' was not found. Please ensure you upload the file with the exact name.\")\n",
        "if 'Test.csv' not in uploaded:\n",
        "    print(\"\\nERROR: 'Test.csv' was not found. Please ensure you upload the file with the exact name.\")\n",
        "\n",
        "# Read the uploaded training and testing data\n",
        "try:\n",
        "    # The user provided Train.xlsx, but it was converted to CSV, let's use the uploaded CSV name\n",
        "    train_data = pd.read_csv(io.BytesIO(uploaded['Train.csv']))\n",
        "    test_template = pd.read_csv(io.BytesIO(uploaded['Test.csv']))\n",
        "    print(\"\\nData files loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during file loading: {e}\")\n",
        "    # Stop execution if files are not loaded\n",
        "    raise\n",
        "\n",
        "# Display the initial structure of the loaded dataframes\n",
        "print(\"\\n--- Train Data Head ---\")\n",
        "print(train_data.head())\n",
        "print(\"\\n--- Test Template Head ---\")\n",
        "print(test_template.head())\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. TRAINING DATA PREPROCESSING (AGGREGATION)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting data preprocessing...\")\n",
        "\n",
        "# Convert 'YEAR' and 'MONTH' to a single datetime index (Time Series requires aggregation)\n",
        "# We assume the 1st of the month for all entries.\n",
        "train_data['DATE'] = pd.to_datetime(train_data['YEAR'].astype(str) + '-' + train_data['MONTH'].astype(str) + '-01')\n",
        "\n",
        "# The goal is to forecast the COUNT of incidents, so we group the individual records\n",
        "# by their date and crime type and count the occurrences.\n",
        "ts_data = train_data.groupby(['DATE', 'TYPE']).size().reset_index(name='COUNT')\n",
        "\n",
        "# Rename columns to Prophet's required format: ds (date) and y (value)\n",
        "ts_data.columns = ['ds', 'TYPE', 'y']\n",
        "\n",
        "# Display the aggregated time series data\n",
        "print(\"\\n--- Aggregated Time Series Data Head ---\")\n",
        "print(ts_data.head())\n",
        "print(f\"Total number of time series: {ts_data['TYPE'].nunique()}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MODEL TRAINING AND FORECASTING\n",
        "# ==============================================================================\n",
        "\n",
        "# Create a container to store the results\n",
        "all_forecasts = []\n",
        "unique_types = ts_data['TYPE'].unique()\n",
        "\n",
        "for crime_type in unique_types:\n",
        "    print(f\"\\nTraining and forecasting for: {crime_type}...\")\n",
        "\n",
        "    # a) Filter the data for the current crime type\n",
        "    df_type = ts_data[ts_data['TYPE'] == crime_type].copy()\n",
        "\n",
        "    # b) Initialize and fit the Prophet model\n",
        "    # Set daily_seasonality=False for monthly data, weekly_seasonality=False.\n",
        "    # Add yearly seasonality which is common in crime data.\n",
        "    model = Prophet(\n",
        "        yearly_seasonality=True,\n",
        "        daily_seasonality=False,\n",
        "        weekly_seasonality=False,\n",
        "        interval_width=0.95  # 95% confidence interval\n",
        "    )\n",
        "    model.fit(df_type)\n",
        "\n",
        "    # c) Prepare the future dates for forecasting (from the Test template)\n",
        "    # The test template has the exact YEAR/MONTH/TYPE combinations we need to predict\n",
        "    future_test = test_template[test_template['TYPE'] == crime_type].copy()\n",
        "    future_test['DATE'] = pd.to_datetime(future_test['YEAR'].astype(str) + '-' + future_test['MONTH'].astype(str) + '-01')\n",
        "    future_test = future_test.rename(columns={'DATE': 'ds'})\n",
        "\n",
        "    # d) Generate the forecast\n",
        "    # We only need the 'ds' column for the forecast\n",
        "    future_dates = future_test[['ds']]\n",
        "    forecast = model.predict(future_dates)\n",
        "\n",
        "    # e) Extract the prediction (yhat) and combine with the original test template columns\n",
        "    # 'yhat' is the point forecast.\n",
        "    forecast_df = future_test[['YEAR', 'MONTH', 'TYPE']].copy()\n",
        "    forecast_df['Incident_Counts'] = forecast['yhat'].round().astype(int) # Round to nearest integer count\n",
        "\n",
        "    # Append to the results list\n",
        "    all_forecasts.append(forecast_df)\n",
        "\n",
        "    # Optional: Plot the forecast for a visual check\n",
        "    # fig = model.plot(forecast)\n",
        "    # plt.title(f\"Forecast for {crime_type}\")\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. FINAL OUTPUT AND SUBMISSION FILE GENERATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n--- Generating final submission file ---\")\n",
        "\n",
        "# Combine all individual crime type forecasts into a single DataFrame\n",
        "submission_df = pd.concat(all_forecasts)\n",
        "\n",
        "# Merge the predicted counts back into the original test template structure.\n",
        "# We will use the columns that uniquely identify the rows in Test (2).csv\n",
        "final_submission = pd.merge(\n",
        "    test_template[['YEAR', 'MONTH', 'TYPE']],\n",
        "    submission_df[['YEAR', 'MONTH', 'TYPE', 'Incident_Counts']],\n",
        "    on=['YEAR', 'MONTH', 'TYPE'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Replace any NaN (if a crime type was in the test but not in the train, or vice versa) with 0, or simply ensure the merge was clean.\n",
        "# Based on the merge, NaN should only occur if the data is inconsistent. Let's assume a clean merge for now.\n",
        "\n",
        "# Final check of the submission file structure\n",
        "print(\"\\n--- Final Submission File Head ---\")\n",
        "print(final_submission.head())\n",
        "print(f\"Total rows in submission: {len(final_submission)}\")\n",
        "\n",
        "# Save the final DataFrame to a CSV file for submission\n",
        "final_submission.to_csv('FBI_Time_Series_Forecast_Submission.csv', index=False)\n",
        "\n",
        "print(\"\\n--- SUCCESS ---\")\n",
        "print(\"The forecasting is complete. The results have been saved to:\")\n",
        "print(\"FBI_Time_Series_Forecast_Submission.csv\")\n",
        "print(\"You can download the file from the Colab file explorer or by running the following command:\")\n",
        "\n",
        "# Command to download the file directly\n",
        "files.download('FBI_Time_Series_Forecast_Submission.csv')"
      ]
    }
  ]
}